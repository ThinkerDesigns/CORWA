[BOS] Computing new information is useful in many applications.
[BOS] The TREC novelty tasks (Allan et al., 2003; Soboroff and Harman, 2005; Schiffman, 2005) tested the ability of systems to find novel information in an IR setting.
[BOS] Systems were given a list of documents ranked according to relevance to a query.
[BOS] The goal is to find sentences in each document which are relevant to the query, and at the same time is new information given the content of documents higher in the relevance list.

[BOS] For update summarization of news, methods range from textual entailment techniques (Bentivogli et al., 2010) to find facts in the input which are not entailed by the background, to Bayesian topic models (Delort and Alfonseca, 2012) which aim to learn and use topics discussed only in background, those only in the update input and those that overlap across the two sets.

[BOS] Even for generic summarization, some of the best results were obtained by Conroy et al. (2006) by using a large random corpus of news articles as the background while summarizing a new article, an idea first proposed by Lin and Hovy (2000) .
[BOS] Central to this approach is the use of a likelihood ratio test to compute topic words, words that have significantly higher probability in the input compared to the background corpus, and are hence descriptive of the input's topic.
[BOS] In this work, we compare our system to topic word based ones since the latter is also a general method to find surprising new words in a set of input documents but is not a bayesian approach.
[BOS] We briefly explain the topic words based approach below.

[BOS] Computing topic words: Let us call the input set I and the background B.
[BOS] The log-likelihood ratio test compares two hypotheses:

[BOS] H 1 : A word t is not a topic word and occurs with equal probability in I and B, i.e. p(t|I) = p(t|B) = p H 2 : t is a topic word, hence p(t|I) = p 1 and p(t|B) = p 2 and p 1 > p 2 A set of documents D containing N tokens is viewed as a sequence of words w 1 w 2 ...w N .
[BOS] The word in each position i is assumed to be generated by a Bernoulli trial which succeeds when the generated word w i = t and fails when w i is not t. Suppose that the probability of success is p. Then the probability of a word t appearing k times in a dataset of N tokens is the binomial probability:

[BOS] The likelihood ratio compares the likelihood of the data D = {B, I} under the two hypotheses.

[BOS] p, p 1 and p 2 are estimated by maximum likelihood.
[BOS] p = c t /N where c t is the number of times word t appears in the total set of tokens comprising {B, I}.
[BOS] p 1 = c I t /N I and p 2 = c B t /N B are the probabilities of t estimated only from the input and only from the background respectively.

[BOS] A convenient aspect of this approach is that 2 log  is asymptotically  2 distributed.
[BOS] So for a resulting 2 log  value, we can use the  2 table to find the significance level with which the null hypothesis H 1 can be rejected.
[BOS] For example, a value of 10 corresponds to a significance level of 0.001 and is standardly used as the cutoff.
[BOS] Words with 2 log  > 10 are considered topic words.
[BOS] Conroy et al. (2006)'s system gives a weight of 1 to the topic words and scores sentences using the number of topic words normalized by sentence length.

