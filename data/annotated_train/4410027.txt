[BOS] Word sense disambiguation (WSD), the task of determining the correct meaning or sense of a word in context is a long standing task in NLP (Yarowsky, 1995; Ng and Lee, 1996; Mihalcea and Faruque, 2004; Navigli, 2009; Zhong and Ng, 2010; Di Marco and Navigli, 2013; Chen et al., 2014; Camacho-Collados et al., 2015) .
[BOS] Recent research on tackling WSD and capturing multi-senses includes work leveraging LSTM (Kgebck and Salomonsson, 2016; Yuan et al., 2016) , which we extended as a context network in our paper and predicting senses with word embeddings that capture context (Kgebck and Sa- (ref), the translation generated by our best context-aware model (best), and the translation generated by baseline model (base).
[BOS] We also highlight the word with multiple senses in source language in bold, the corresponding correctly translated words in blue and wrongly translated words in red.
[BOS] The definitions of words in blue or red are in parenthesis.
[BOS] lomonsson, 2016; Yuan et al., 2016) .
[BOS] uster et al. (2016) ; Kawakami and Dyer (2016) also showed that bilingual data improves WSD.

[BOS] In contrast to the standard WSD formulation, Vickrey et al. (2005) reformulated the task of WSD for Statistical Machine Translation (SMT) as predicting possible target translations which directly improves the accuracy of machine translation.
[BOS] Following this reformulation, Chan et al. (2007) ; Carpuat and Wu (2007a,b) integrated WSD systems into phrase-based systems.
[BOS] Xiong and Zhang (2014) breaks the process into two stages.
[BOS] First predicts the sense of the ambiguous source word.
[BOS] The predicted word senses together with other context features are then used to predict possible target translation.

[BOS] Within the framework of Neural MT, there is one work that has similar motivation to ours.
[BOS] Choi et al. (2017) leverage the NBOW as context and gate the word-embedding on both encoder and decoder side.
[BOS] However, their work does not distinguish context vectors for words in the same sequence, in contrast to the method in this paper, and our results demonstrate that this is an important feature of methods that handle homographs in NMT.
[BOS] In addition, our quantitative analysis of the problems that homographs pose to NMT and evaluation of how context-aware models fix them was not covered in this previous work.

